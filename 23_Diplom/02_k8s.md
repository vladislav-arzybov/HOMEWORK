### Создание Kubernetes кластера

На этом этапе необходимо создать [Kubernetes](https://kubernetes.io/ru/docs/concepts/overview/what-is-kubernetes/) кластер на базе предварительно созданной инфраструктуры.   Требуется обеспечить доступ к ресурсам из Интернета.

Это можно сделать двумя способами:

1. Рекомендуемый вариант: самостоятельная установка Kubernetes кластера.  
   а. При помощи Terraform подготовить как минимум 3 виртуальных машины Compute Cloud для создания Kubernetes-кластера. Тип виртуальной машины следует выбрать самостоятельно с учётом требовании к производительности и стоимости. Если в дальнейшем поймете, что необходимо сменить тип инстанса, используйте Terraform для внесения изменений.

> Через Terraform подготовим 1 master ноду и 2 worker ноды. Для создания я использовал цикл for_each, т.к. он позволяет удобно задать имена и ресурсы ВМ.



   б. Подготовить [ansible](https://www.ansible.com/) конфигурации, можно воспользоваться, например [Kubespray](https://wiki.blacksoft.pro/ru/DevOps/Kubernetes/%D0%A1%D0%BE%D0%B7%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5-%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B0-kubespray)  
   в. Задеплоить Kubernetes на подготовленные ранее инстансы, в случае нехватки каких-либо ресурсов вы всегда можете создать их при помощи Terraform.
3. Альтернативный вариант: воспользуйтесь сервисом [Yandex Managed Service for Kubernetes](https://cloud.yandex.ru/services/managed-kubernetes)  
  а. С помощью terraform resource для [kubernetes](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/kubernetes_cluster) создать **региональный** мастер kubernetes с размещением нод в разных 3 подсетях      
  б. С помощью terraform resource для [kubernetes node group](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/kubernetes_node_group)
  
Ожидаемый результат:

1. Работоспособный Kubernetes кластер.
2. В файле `~/.kube/config` находятся данные для доступа к кластеру.
3. Команда `kubectl get pods --all-namespaces` отрабатывает без ошибок.


### РЕШЕНИЕ:
> Запуск с локального хоста на мастер ноде, прокидывание приватного ключа:
- ansible-playbook -i ansible/inventory/inventory.ini ansible/site.yaml

> Обновить TLS-сертификат Kubernetes API-сервера и включить в него внешний IP-адрес моего хоста
- Правим: inventory/<your_cluster>/group_vars/k8s_cluster/k8s-cluster.yml, строку:

```
supplementary_addresses_in_ssl_keys:
  - 89.169.135.188
```

- ansible-playbook -i inventory/mycluster/inventory.ini   --become --become-user=root   cluster.yml   -t "k8s-certificates"

- Повторно копируем конфиг и выдаем права:

```bash
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

> Копирование конфига k8s на локальный хост
- scp reivol@89.169.135.188:/home/reivol/.kube/config /home/reivol/.kube/
- В конфиге /home/reivol/.kube/config, правим: server: https://127.0.0.1:6443, на server: https://89.169.135.188:6443 (внещний ip master-node)
- Проверяем: kubectl get pods --all-namespaces

> Правка файлов при первом запуске: supplementary_addresses_in_ssl_keys: [10.0.0.1, 10.0.0.2, 10.0.0.3, 46.21.245.44, 109.196.195.164]
- /home/reivol/kubespray/inventory/mycluster/group_vars/all/all.yml
- /home/reivol/kubespray/inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml

> Узнать внешний ip из консоли:
- curl 2ip.ru


На мастер ноде установить:
- python3-pip
- ansible


#####################################
> На мастер ноде, автоматизировать в ансибл
- git clone https://github.com/kubernetes-sigs/kubespray.git
- sudo apt update
- sudo apt install python3-pip
- sudo apt install ansible
- cd kubespray
- pip install -r requirements.txt

> Копируем шаблон в новый каталог
- cp -rfp inventory/sample/ inventory/mycluster

> Правим инвентари, копируем созданный!
- nano inventory/mycluster/inventory.ini

> Правим адрес мастер ноды!: supplementary_addresses_in_ssl_keys: [178.155.18.16]
- /home/reivol/kubespray/inventory/mycluster/group_vars/all/all.yml
- /home/reivol/kubespray/inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml

> Запускаем установку
- ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b -v

> На мастер ноде
- mkdir -p $HOME/.kube
- sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
- sudo chown $(id -u):$(id -g) $HOME/.kube/config

- kubectl get nodes
- kubectl get pods --all-namespaces

> На лок хосте: адрес мастер ноды
- scp reivol@89.169.155.95:/home/reivol/.kube/config /home/reivol/.kube/
- nano /home/reivol/.kube/config
- kubectl get pods --all-namespaces


<img width="840" height="370" alt="изображение" src="https://github.com/user-attachments/assets/5e644d47-8059-4f98-af26-3d7c9d69f404" />

